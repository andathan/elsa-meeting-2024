<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: March 18, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  
    
    <script src="/ethicalai/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/ethicalai/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/ethicalai/css/wowchemy.2b0f89e1d06dd9aefe660591a142e8b6.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/ethicalai/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/ethicalai/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



































  

<meta name="description" content="" />



<link rel="alternate" hreflang="en-us" href="https://lix.polytechnique.fr/ethicalai/presentations/alina-leidinger/" />
<link rel="canonical" href="https://lix.polytechnique.fr/ethicalai/presentations/alina-leidinger/" />



  <link rel="manifest" href="/ethicalai/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/ethicalai/media/icon_huea1068804100d8e5c82b358e272b90a5_10897_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/ethicalai/media/icon_huea1068804100d8e5c82b358e272b90a5_10897_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />
<meta property="twitter:image" content="https://lix.polytechnique.fr/ethicalai/media/logo_hu1eb3cadf74eada81710e9b6c954372bc_19821_300x300_fit_lanczos_3.png" />
<meta property="og:site_name" content="Comete Ethical AI Workshop" />
<meta property="og:url" content="https://lix.polytechnique.fr/ethicalai/presentations/alina-leidinger/" />
<meta property="og:title" content="How safe are LLMs compared to search engine autocompletions? A bias check-up | Comete Ethical AI Workshop" />
<meta property="og:description" content="" /><meta property="og:image" content="https://lix.polytechnique.fr/ethicalai/media/logo_hu1eb3cadf74eada81710e9b6c954372bc_19821_300x300_fit_lanczos_3.png" /><meta property="og:locale" content="en-us" />

  
  







  




  
  
  

  
  

  
  
  
  
  
    <script src="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.js" integrity="sha512-yXXqOFjdjHNH1GND+1EO0jbvvebABpzGKD66djnUfiKlYME5HGMUJHoCaeE4D5PTG2YsSJf6dwqyUUvQvS0vaA==" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.css" integrity="sha512-LQ97camar/lOliT/MqjcQs5kWgy6Qz/cCRzzRzUCfv0fotsCTC9ZHXaPQmJV8Xu/PVALfJZ7BDezl5lW3/qBxg==" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#1565c0",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#1565c0"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://www.cookiesandyou.com"
      }
    })});
  </script>



  
  <title>How safe are LLMs compared to search engine autocompletions? A bias check-up | Comete Ethical AI Workshop</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="bb4fbde3aa0b39a88faebd5a6bc31e50" >

  
  
  
  
  
  
  
  
  
  <script src="/ethicalai/js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  











  


<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/ethicalai/"><img src="/ethicalai/media/logo_hu1eb3cadf74eada81710e9b6c954372bc_19821_0x70_resize_lanczos_3.png" alt="Comete Ethical AI Workshop" height="auto"
            
            ></a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/ethicalai/"><img src="/ethicalai/media/logo_hu1eb3cadf74eada81710e9b6c954372bc_19821_0x70_resize_lanczos_3.png" alt="Comete Ethical AI Workshop" height="auto"
          
          ></a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/ethicalai/#about"><span>About</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/ethicalai/#keynotes"><span>Keynotes</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/ethicalai/#programme"><span>Programme</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/ethicalai/#venue"><span>Venue</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/ethicalai/#organizers"><span>Organizers</span></a>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Previous editions</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/ethicalai/previous/2022/"><span>2022</span></a>
              
            </div>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        

        
        
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>



  </div>

  <div class="page-body">
    
    
    

    

<span class="js-widget-page d-none"></span>



  
























































<section id="section-markdown" class="home-section wg-markdown  "  >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  
    <div class="row  justify-content-center">
    
      
        <div class="section-heading col-12 mb-3 text-center">
          <h1 class="mb-0">How safe are LLMs compared to search engine autocompletions? A bias check-up</h1>
          <p class="mt-1">Alina Leidinger <br/> <em>University of Amsterdam</em></p>
        </div>
      
    
  

    










  <div class="col-12">
    <p>To what extent do publicly and commercially available LLMs repeat and reinforce the biases found in commercial search engine autocompletions? The research examines the stereotype-evoking prompts made to Google, Yahoo! and DuckDuckGo autocompletion in 2022 where we found significant differences between the engines&rsquo; content moderation (Leidinger and Rogers, 2023). While Google and to a lesser extent DuckDuckGo moderate stereotypes, Yahoo! provides far more license to them. The stereotype-eliciting prompts were re-run across three LLMs in order to test for safe model behaviours, i.e., refusal to answer, with results that vary quite significantly, both between commercial and open source models. Notably often we find that models partially refuse (Rottger et al. 2023) highlighting a tension between model helpfulness and harmlessness (Askell et al. 2021).</p>
<p>References:</p>
<p>Askell, Amanda, et al. &ldquo;A general language assistant as a laboratory for alignment.&rdquo; arXiv preprint arXiv:2112.00861 (2021).
Leidinger, Alina, and Richard Rogers. &ldquo;Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion?.&rdquo; Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency. 2023.</p>
<p>Safiya Umoja Noble. 2018. Algorithms of oppression. New York University Press.</p>
<p>Röttger, Paul, et al. &ldquo;Xstest: A test suite for identifying exaggerated safety behaviours in large language models.&rdquo; arXiv preprint arXiv:2308.01263 (2023).</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.</p>
<p>OpenAI. 2023a. <a href="https://platform.openai.com/docs/guides/moderation/overview" target="_blank" rel="noopener">https://platform.openai.com/docs/guides/moderation/overview</a>
Almazrouei, Ebtesam, et al. Falcon-40B: an open large language model with state-of-the-art performance. Technical report, Technology Innovation Institute, 2023.</p>

  </div>



  
    </div>
  

  </div>
</section>



  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/ethicalai/js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/ethicalai/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/ethicalai/en/js/wowchemy.min.4922cd6d3d810ab587afa7cdb3851db6.js"></script>



  <script src="/ethicalai/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>






















</body>
</html>
